version: "3.9"
services:
  llm:
    build: .
    container_name: llm-api
    ports:
      - "8658:8000"
    volumes:
      - /data/llm:/models
    restart: unless-stopped

